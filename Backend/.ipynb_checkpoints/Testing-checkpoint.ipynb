{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "class CSV:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    def add_block(self, block):\n",
    "\n",
    "        with open(\"storage/blockchain.csv\", 'a+', newline='') as blockchain:\n",
    "            writer = csv.writer(blockchain)\n",
    "            writer.writerow(json.dumps(block)\n",
    "\n",
    "\n",
    "    def add_adress(self, address):\n",
    "\n",
    "        with open(\"storage/adresses.csv\", \"'a+', newline=''\") as adresses:\n",
    "            csv_writer = csv.writer(adresses)\n",
    "            csv_writer.writerow(\"adress\")\n",
    "            \n",
    "    def get_entries(self, _ids):\n",
    "        \n",
    "        \n",
    "        with open(\"storage/blockchain.csv\") as blockchain:\n",
    "\n",
    "            csv_reader = csv.DictReader(blockchain)\n",
    "            return [dict(row) for row in csv_reader if dict(row)[\"_id\"] in _ids]\n",
    "        \n",
    "\n",
    "    def read_chain(self):\n",
    "\n",
    "        \"\"\"\n",
    "        generator to go through blockchain and return consecutive blocks\n",
    "        \"\"\"\n",
    "\n",
    "        with open(\"storage/blockchain.csv\") as blockchain1:\n",
    "\n",
    "            with open(\"storage/blockchain.csv\") as blockchain2:\n",
    "\n",
    "                previous_blocks = csv.reader(blockchain1)\n",
    "                current_blocks = csv.reader(blockchain2)\n",
    "                next(current_blocks)\n",
    "\n",
    "                for previous_block, current_block in zip(previous_blocks, current_blocks):\n",
    "                    yield json.loads(previous_block), json.loads(current_block)\n",
    "\n",
    "    def get_last_block(self):\n",
    "\n",
    "        \"\"\"\n",
    "        this should be done in a more efficent way\n",
    "        \"\"\"\n",
    "\n",
    "        with open(\"storage/blockchain.csv\") as blockchain:\n",
    "\n",
    "            csv_reader = csv.DictReader(blockchain)\n",
    "        \n",
    "            for _ in range(1,self.get_chain_length()):\n",
    "\n",
    "                next(csv_reader)\n",
    "\n",
    "            return dict([row for row in csv_reader][0])\n",
    "        \n",
    "\n",
    "    def read_adresses(self):\n",
    "\n",
    "        \"\"\"\n",
    "        generator to yield adresses, row for row\n",
    "        \"\"\"\n",
    "\n",
    "        with open(\"storage/adresses.csv\") as addresses:\n",
    "\n",
    "            csv_reader = csv.reader(addresses)\n",
    "            for row in csv_reader:\n",
    "\n",
    "                yield row\n",
    "\n",
    "\n",
    "    def get_chain_length(self):\n",
    "\n",
    "        with open(\"storage/blockchain.csv\") as blockchain:\n",
    "\n",
    "            csv_reader = csv.DictReader(blockchain)\n",
    "            return sum(1 for row in csv_reader)\n",
    "        \n",
    "        \n",
    "import pymongo\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class DBConnect:\n",
    "    \n",
    "    \"\"\"\n",
    "    Connects to MongoDB database; has two methods:\n",
    "    1. to ingest a block \n",
    "    2. to query documents according to car_id\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        load_dotenv()\n",
    "        self.USER_NAME = os.getenv(\"USER_NAME\")\n",
    "        self.PASSWORD = os.getenv(\"PASSWORD\")\n",
    "        self.DATA_BASE = os.getenv(\"DATA_BASE\")\n",
    "        mongo_client = pymongo.MongoClient(\n",
    "            f\"mongodb+srv://{self.USER_NAME}:{self.PASSWORD}@cluster0.e1xus.mongodb.net/{self.DATA_BASE}?retryWrites=true&w=majority\")\n",
    "        db = mongo_client.CarChain\n",
    "        self.storage = db.CarChainStorage\n",
    "        \n",
    "    def ingest_block(self, block):\n",
    "        \n",
    "        self.storage.insert(block)\n",
    "        \n",
    "       \n",
    "    def get_car_history(self, car_id):\n",
    "    \n",
    "        \"\"\"\n",
    "        method to query all entries in data base of a given car_id\n",
    "        \n",
    "        error handling for unknown key is still missing\n",
    "        \"\"\"\n",
    "        return sorted([item for item in self.storage.find({\"car_id\":car_id})], key = lambda i: i[\"_id\"])\n",
    "        \n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "\n",
    "class Blockchain:\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.csv_operator = CSV()\n",
    "        \n",
    "    def get_hash(self, block):\n",
    "        \n",
    "        encoded_block = json.dumps(block, sort_keys = True).encode()\n",
    "        return hashlib.sha256(encoded_block).hexdigest()\n",
    "\n",
    "    def proof_of_work(self, previous_nonce):\n",
    "        new_nonce = 1\n",
    "        check_nonce = True\n",
    "        while check_nonce:\n",
    "            hash_operation = hashlib.sha256(str(new_nonce**2 - previous_nonce**2).encode()).hexdigest()\n",
    "            if hash_operation[:4] == '0000':\n",
    "                check_nonce = False\n",
    "            else:\n",
    "                new_nonce += 1\n",
    "        return new_nonce\n",
    "    \n",
    "    def chain_is_valid(self):\n",
    "\n",
    "        for previous_block, current_block in self.csv_operator.read_chain():\n",
    "            \n",
    "            if self.get_hash(previous_block) != current_block[\"block_hash\"]:\n",
    "                \n",
    "                return False\n",
    "            \n",
    "            hash_operation = hashlib.sha256(str(int(current_block[\"nonce\"])**2 - int(previous_block[\"nonce\"])**2).encode()).hexdigest()\n",
    "            if hash_operation[:4] != '0000':\n",
    "\n",
    "                return False\n",
    "           \n",
    "        return True\n",
    "    \n",
    "                        \n",
    "    def mine_block(self, block_type, block_data):\n",
    "        \n",
    "        client = DBConnect()\n",
    "        \n",
    "        last_block = self.csv_operator.get_last_block()\n",
    "        _id = self.csv_operator.get_chain_length()\n",
    "        car_id = block_data[0]\n",
    "        nonce = self.proof_of_work(int(last_block[\"nonce\"]))\n",
    "        last_hash_block = self.get_hash(last_block)\n",
    "        last_hash_car = \"None\"\n",
    "        \n",
    "        if block_type == \"Production\":\n",
    "            \n",
    "            block = {\"_id\":_id,\n",
    "                     \"car_id\":car_id,\n",
    "                     \"nonce\":nonce,\n",
    "                     \"car_hash\":last_hash_car,\n",
    "                     \"block_hash\":last_hash_block,\n",
    "                     \"details\": \"Production \"  \n",
    "            }\n",
    "            \n",
    "        elif block_type == \"NewRegister\":\n",
    "            \n",
    "            block = {\"_id\":_id,\n",
    "                     \"car_id\":car_id,\n",
    "                     \"nonce\":nonce,\n",
    "                     \"car_hash\":last_hash_car,\n",
    "                     \"block_hash\":last_hash_block,\n",
    "                     \"details\": \"NewRegister \"  \n",
    "            }\n",
    "                                 \n",
    "        elif block_type == \"Repair\":\n",
    "            \n",
    "            last_car_entry = client.get_car_history(car_id)[-1]\n",
    "            last_hash_car = self.get_hash(last_car_entry)            \n",
    "            \n",
    "            block = {\"_id\":_id,\n",
    "                     \"car_id\":car_id,\n",
    "                     \"nonce\":nonce,\n",
    "                     \"car_hash\":last_hash_car,\n",
    "                     \"block_hash\":last_hash_block,\n",
    "                     \"details\": \"Repair\"  \n",
    "            }\n",
    "         \n",
    "        elif block_type == \"Sale\":\n",
    "            \n",
    "            last_car_entry = client.get_car_history(car_id)[-1]\n",
    "            last_hash_car = self.get_hash(last_car_entry)    \n",
    "            \n",
    "            block = {\"_id\":_id,\n",
    "                     \"car_id\":car_id,\n",
    "                     \"nonce\":nonce,\n",
    "                     \"car_hash\":last_hash_car,\n",
    "                     \"block_hash\":last_hash_block,\n",
    "                     \"details\": \"Sale \"  \n",
    "            }                                             \n",
    "        else:\n",
    "        \n",
    "            return \"wrong input\"\n",
    "        \n",
    "        client.ingest_block(block)\n",
    "        self.csv_operator.add_block(block)\n",
    "        \n",
    "          \n",
    "    def car_history_is_valid(self,car_id):\n",
    "        \n",
    "        \"\"\"\n",
    "        car history is valid if\n",
    "        1. chain is valid\n",
    "        2. entries in data base match corresponding chain entries\n",
    "        3. the hashes that link the car history are valid\n",
    "        \"\"\"\n",
    "  \n",
    "        if self.chain_is_valid():\n",
    "        \n",
    "            client = DBConnect()\n",
    "            car_history = client.get_car_history(car_id)\n",
    "            car_history_ids = [str(stage[\"_id\"]) for stage in car_history]\n",
    "            print(car_history_ids)\n",
    "            print(car_history)\n",
    "            print(self.csv_operator.get_entries(car_history_ids))\n",
    "            \n",
    "            # find entries in blockchain that have matching _id to car_history_ids\n",
    "            \n",
    "            if car_history != self.csv_operator.get_entries(car_history_ids):\n",
    "            \n",
    "                return False\n",
    "            \n",
    "            if len(car_history) <= 1:\n",
    "                \n",
    "                return True\n",
    "            \n",
    "            index = 1\n",
    "            \n",
    "            while index < len(car_history):\n",
    "                \n",
    "                if self.get_hash(car_history[index -1]) != car_history[index][\"hash\"][\"car\"]:\n",
    "                    \n",
    "                    return False\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "            return True\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            return False\n",
    "        \n",
    "    def replace_chain(self): \n",
    "        \n",
    "        longest_chain = None\n",
    "        max_length = len(self.chain)\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            response = requests.get(f'http://{node}/get_chain')\n",
    "            if response.status_code == 200:\n",
    "                length = response.json()['length']\n",
    "                chain = response.json()['chain']\n",
    "                if length > max_length and self.is_chain_valid(chain):\n",
    "                    max_length = length\n",
    "                    longest_chain = chain\n",
    "        if longest_chain:\n",
    "            self.chain = longest_chain\n",
    "            return True\n",
    "        return False\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX490\\Anaconda3\\envs\\spotify\\lib\\site-packages\\ipykernel_launcher.py:112: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-eabf013209b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#test.csv_operator.get_last_block()[\"nonce\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmine_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Production\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"1111\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmine_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sale\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"1111\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmine_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Repair\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"1111\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-154849d53e04>\u001b[0m in \u001b[0;36mmine_block\u001b[1;34m(self, block_type, block_data)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mcar_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mnonce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproof_of_work\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nonce\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mlast_hash_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[0mlast_hash_car\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-154849d53e04>\u001b[0m in \u001b[0;36mget_hash\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mencoded_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\spotify\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         **kw).encode(obj)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\spotify\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\spotify\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "client = DBConnect()\n",
    "client.storage.drop()\n",
    "test = Blockchain()\n",
    "#test.csv_operator.get_last_block()[\"nonce\"]\n",
    "test.mine_block(\"Production\", [\"1111\"])\n",
    "test.mine_block(\"Sale\",[\"1111\"])\n",
    "test.mine_block(\"Repair\", [\"1111\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n",
      "[{'_id': 1, 'car_id': '1111', 'nonce': 115558, 'car_hash': 'None', 'block_hash': '5a75269d87b4a32e1afe1603c6aa4af92b9d931edc8b7c5a5a661c0d4b007d1c', 'details': 'Production '}, {'_id': 2, 'car_id': '1111', 'nonce': 48245, 'car_hash': 'e7fe158fffa1786b36fa7d5cf6e8fd4af25fcb9511746095e79ff8826c6e60a7', 'block_hash': '9079400ed4613f157b4baeb201894cf8ce9806de44f2e39bc6705744dc77d947', 'details': 'Sale '}, {'_id': 3, 'car_id': '1111', 'nonce': 93823, 'car_hash': 'd61649fa91b5fb1b5aaf1c6b51ae0dfacd5679ce6168630cbabd7e8601f6e431', 'block_hash': '8f093a468d864fa1b481326cd381e6cece13e9473066bdd45b4cef7e04627399', 'details': 'Repair'}]\n",
      "[{'_id': '1', 'car_id': '1111', 'nonce': '115558', 'car_hash': 'None', 'block_hash': '5a75269d87b4a32e1afe1603c6aa4af92b9d931edc8b7c5a5a661c0d4b007d1c', 'details': 'Production '}, {'_id': '2', 'car_id': '1111', 'nonce': '48245', 'car_hash': 'e7fe158fffa1786b36fa7d5cf6e8fd4af25fcb9511746095e79ff8826c6e60a7', 'block_hash': '9079400ed4613f157b4baeb201894cf8ce9806de44f2e39bc6705744dc77d947', 'details': 'Sale '}, {'_id': '3', 'car_id': '1111', 'nonce': '93823', 'car_hash': 'd61649fa91b5fb1b5aaf1c6b51ae0dfacd5679ce6168630cbabd7e8601f6e431', 'block_hash': '8f093a468d864fa1b481326cd381e6cece13e9473066bdd45b4cef7e04627399', 'details': 'Repair'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Blockchain()\n",
    "\n",
    "#test.chain_is_valid()\n",
    "\n",
    "#client.get_car_history(\"1111\")\n",
    "test.car_history_is_valid(\"1111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('2', '3'), ('None', 'None'), ('0', '0'), (\"{'block': 'None', 'car': 'None'}\", \"{'block': 'None', 'car': 'None'}\"), (\"{'Sale': 'None'}\", \"{'Sale': 'None'}\")])\n"
     ]
    }
   ],
   "source": [
    "with open(\"storage/blockchain.csv\") as blockchain:\n",
    "\n",
    "    block_reader = csv.DictReader(blockchain)\n",
    "    hash_reader = csv.DictReader(blockchain)\n",
    "    next(hash_reader)\n",
    "    \n",
    "    for row in block_reader:\n",
    "        \n",
    "        print(row)\n",
    "    \n",
    "    \n",
    "\n",
    "    #for block, hashed_block in zip(block_reader, hash_reader):\n",
    "        #print(block, hashed_block)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "with open(\"storage/blockchain.csv\") as blockchain:\n",
    "    \n",
    "    blockchain.seek(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '1',\n",
       "  'car_id': '1111',\n",
       "  'nonce': '115558',\n",
       "  'car_hash': 'None',\n",
       "  'block_hash': '5a75269d87b4a32e1afe1603c6aa4af92b9d931edc8b7c5a5a661c0d4b007d1c',\n",
       "  'details': 'Production '}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"storage/blockchain.csv\") as blockchain:\n",
    "\n",
    "    csv_reader = csv.DictReader(blockchain)\n",
    "    test = [dict(row) for row in csv_reader if dict(row)[\"_id\"] == \"1\" ]\n",
    "    \n",
    "test\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'fp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7089023000b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"hello\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: dump() missing 1 required positional argument: 'fp'"
     ]
    }
   ],
   "source": [
    "json.dump({\"hello\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"hello\": 0}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = json.dumps({\"hello\":0}, sort_keys = True).encode()\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(block)[\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"storage/blockchain.csv\", 'a+', newline='') as blockchain:\n",
    "    \n",
    "    writer = csv.writer(blockchain)\n",
    "    writer.writerow([\"hello\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spotify (Python3)",
   "language": "python",
   "name": "spotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
